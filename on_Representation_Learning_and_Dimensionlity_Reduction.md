# On Manifold Learning and Dimensionality Reduction

*These are mostly notes and thoughts and may contain mistakes*

The aim of this document is to (hopefully) present a unified framework for the molteplicity of available methods which appear in the literature under research fields such as *Manifold Learning*, *Dimensionality Reduction* and *Reduced Order Modeling*. We noticed that oftentimes different research fields use the same methodology (under different names) and never talk to each other, making it difficult for researchers to underpin the actual scientific value of the proposed new methods. We also try to go deeper in the connection between *Manifold Learning* and *Dimensionality Reduction*, in order to clarify the main aim of these research fields. Finally, we focus on the application of such ideas to approximating the evolution over time of high dimensional objects subjected to physical constraints (PDEs/ODEs).

## Introduction
Data Science has established itself in the last decade as a challenging and central field of study, attracting thousands of researchers from different disciplines. Arguably, what makes this field so captivating is the dichotomy between the ease of reach of this field (we can all gather some data) and the difficulty of making sense of such data. In this sense, Data Science is trying to do what Physics has been doing since the $16\,th$ century: given some observations (data) what can we say about the relationship between them (and first of all, is there even a relationship between them)? While Physics is concerned with natural phenomena, Data Science is concerned with any type of phenomena where observations are available; thus Physics is, at least in this respect, a subset of Data Science.

What is special about Physics is the assumption that observations coming from nature obey some laws that can be expressed in mathematical forms: the goal of Physics is thus writing down such mathematical laws and hoping they are backed out by experiments. In other words, physicists are looking for the *generative process* $\mathcal{G}$ that describes the process of physical phenomena. Intuitively, a generative process $\mathcal{G}$ is an operator that, given a (for simplicity finite) vector of variables $\mathbf{z}$, yields the value of the physical quantity of interest on a given spatio-temporal domain. A few examples:
- a point of a given mass $m$ moving within a uniform gravitational field in a $1D$ space, for a given initial position $x_0$ and a given initial velocity $v_0$. The generative process $\mathcal{G}(x,t|x_0, v_0)$ outputs $1$ if the point is found at position $x$ at time $t$ or zero otherwise;
- the amino acid sequence of a protein $\hat{r}$. The generative process $\mathcal{G}(x,y,z|\hat{r})$ outputs $0$ if no atom is present at $(x,y,z)$ and the atomic speces otherwise;
- the pressure field over the Earth sphere for weather forecasting applications. The generative process $\mathcal{G}(\theta,\phi, t|T,\varphi,\lambda,...)$ outputs the pressure value at the point $(\theta,\phi,t )$ for the initial temperature $T$, the humidity $\varphi$ and the solar radiation $\lambda$ and many other parameters.

What is important to understand about the nature of $\mathcal{G}$ is that in practice it performs a mapping from a vector of variables $\mathbf{z}$ to the physical observables value on a requested space-time domain. In the literature, the variables belonging to $\mathbf{z}$ are known as the *generative factors*, or *irreducible representations*: they contain the minumum amount of information that the generative process $\mathcal{G}$ needs in order to compute the physical values.
### Generative factors or system coordinates?
By looking at $\mathcal{G}$, we see it has $2$ type of inputs: the *system coordinates* where the physical variables live (usually of space-time type), and the *generative factors* which condition the system coordinates to a given scenario. This 'conditioning' explains the notation we use; for the mass in a uniform gravitational field example, $\mathcal{G}(x,t|x_0, v_0)$ reads as: tell me whether the mass is at position $x$ at time $t$, *conditioned to the fact that* at $t=0$ it was at position $x_0$ with velocity $v_0$.
## Variation of the generative factors
Although for a given phenomenon we can have a multitude of variables $\mathbf{z}$, in practice we might be interested in studying the generative process where only some of them (or partly) vary. Sticking to the example of the point moving in a uniform gravitational field, we may think about the extreme case of fixing $(x_0,v_0)$ and only studying the value of $\mathcal{G}$ across $(x,t)$. If this sounds fishy and wrong as the form of $\mathcal{G}$ should resemble the 'physically true (platonically)' generative process (i.e., $\mathcal{G}$ should be invariant to the extent we allow the generative factors to vary), by embodying the fundamental physical laws at the earth of the phenomenon, think about how our description of gravity changes from a Newtonian to a General Relativity perspective: depending on how strong the gravitational fields are and how fast objects are moving, we may use for the description of a given physical system a different set of equations, i.e. a different $\mathcal{G}$. Important to notice however, that in this description the different generative processes behave in a hierarchical manner: the generative process that describes general relativity reduces to the generative process of Newtonian mechanics when some generative factors meet a given condition.
## Finding the true generative factors
Let's say we have no clue how points with mass $m$ move within a uniform gravitational field. We thus perform a bunch of experiments and we collect some data where we associate to each point trajectory over space and time the corresponding (supposed) generative factors $(m^i,x_0^i,v_0^i)$, where the index $i$ identifies the $i\, th$ experiment.
## Examples out of physics
circles, cat rotating

## Inductive biases as physical assumptions (conservation of energy)