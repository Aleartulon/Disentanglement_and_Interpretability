physics_model : 'datasets/Molenkamp' # this is the Path to a directory for the training on a given dataset
description : 'VAE/try_KL_1.0/' #for a given dataset, one can train with different hyperparameters, hence the 'description'
epochs: 5000 #maximum number of epochs
dim_parameter: 0  # Number of parameters of the PDE, including time if the function f must depende on time
time_dependence_in_f: false #true if f depende on time as well
learning_rate: 0.0001 #initial learning rate
batch_size: 32 #batch size
loss_coeff_TF_AR_together: [1, 1, 1, 1]  # coefficients that are multiplied to the loss function terms, signaling the relative importance of each
lambda_regularization_max: 1.0 #coefficients in front of the regularization term. For AE it is jusdt L1 norm, for VAE it is KL divergence
lambda_regularization_strength: 0.001 #initial coeffient of the lambda, then increased dinamically during training
k: 4 # stage of the Runge-Kutta solver for the latent dynamics
dim_input: [1, 2]  # first dimension is # of channels (one if the predicted solution is a scalar field), second is spatial dimensions per channel.
gamma_lr: 0.999 # gamma of  tc.optim.lr_scheduler.ExponentialLR()
AR_strength: 1 #initial coeffient of the loss function term L_i^{A,k_2}, then increased dinamically during training
TBPP_dynamic: [1, 20, 20]  # [if 1 k_2 increases dynamically from k_2=1, number of epochs after which k_2 is increased by 1, max rvalue of k_2]
start_backprop: [1, 35]  # Backpropagation strategy: look at function 'advance_from_ic' to see the 3 different options
checkpoint: false  # if true uses existing checkpoint
time_of_AE: 1 # number of initial epochs where only the AutoEncoder is trained, i.e., loss_coeff_TF_AR_together = [1, 0, 0, 0]. In parallel of this a linear warm-up of the learning rate is performed
time_only_TF : 0 #number of initial epochs after warm up where only TF and not AR approach is used
clipping: [0, 2.5] #[if 1 clipping is applied to f, maximum norm allowed to gradients]
side_size : 128 # length of each dimension of the input field
AutoEncoder : "VAE" # defines the type of AutoEncoder used: if 'VAE' a Variational Autoencoder will be used, otherwise a standard AutoEncoder.
which_device : 'cuda:1' #device where to train
num_workers : 8 #number of workers of dataloaders
data_path : '../../../../../scratch/aalelonghi/molenkamp_whole_time_series/' #path of training and validation data
normalization_field_ma : [True, 1.0] # if true, maxima of each dimension of the solution fields are found. If not, dimension 1,2, etc are the maxima of dimension 1,2, etc of the solution field (only one if it is a scalar field)
normalization_field_mi : [True, 0.0] # if true, minima of each dimension of the solution fields are found. If not, dimension 1,2, etc are the minima of dimension 1,2, etc of the solution field (only one if it is a scalar field)
normalization_parameters_ma : [True, 0.0] #if True, maxima of each dimension of the vector of parameters are found. If not, dimension 1,2, etc are the maxima of dimension 1,2, etc of the parameter vector
normalization_parameters_mi : [True, 0.0] #if True, minima of each dimension of the vector of parameters are found. If not, dimension 1,2, etc are the minima of dimension 1,2, etc of the parameter vector
is_coupled : [false, 'AE'] #if true the AutoEncoder (AE) is trained coupled with the NODE. if false, if 'AE' the AE or VAE are trained, if 'NODE' the NODE is trained.
loss_coeff_not_coupled : [1, 0, 0, 0] #if is_coupled[0] == false, adjust accordingly the loss coefficients
path_trained_AE : 'datasets/burgers/not_coupled' #if is_coupled : [false, 'NODE'], provide the path to the models weights of the AE
