kernel_encoder: [5, 5, 3, 3, 3, 3, 3] #kernels sizes of the Encoder
filters_encoder: [8, 16, 32, 64, 64, 64, 64] #number of filters of the Encoder
stride_encoder: [1, 2, 2, 2, 2, 2, 2] #strides of the Encoder
latent_dimension: 3 #dimension of the latent space
kernel_decoder: [4, 4, 4, 4, 4, 4, 3] #kernels sizes of the Decoder
number_channels_input_cnns_deco : 64
filters_decoder: [64, 64, 64, 64, 32, 16] #number of filters of the Decoder. Last one must be 2 for means anche variances
stride_decoder: [2, 2, 2, 2, 2, 2, 1] #strides of the Decoder
final_and_initial_activation: false #if true, after the final linear layer of the encoder and the initial linear layer of the decoder an activation function is used
training_loss_coefficients: #specifies the coefficients of the loss
  l_reconstruction: 1.0 #reconstruciton of the image
  l_invertible: 1.0
  l_regularization: 1.0 #L1 regularization of the latent space
  total: None
validation_loss_coefficients: #specifies the coefficients of the loss
  l_reconstruction: 1.0 #reconstruciton of the image
  l_invertible: 1.0
  l_reconstruction_unnormed: 1.0 #reconstruciton of the image, unnormalized.
  l_regularization: 0.0 #L1 regularization of the latent space
  total: None #total loss, coefficient
dynamically_increasing_losses:
  l_regularization_strength: 0.01 #initial strength of the l_regularization term. At each epoch a quantity equal to l_regularization_strength is added to l_regularization/l_regularization_strength
weight_decay:
  encoder: 0.0
  decoder: 0.0


